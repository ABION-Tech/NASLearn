<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Deep Learning and Neural Networks - Week 7</title>
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            background-color: #ffffff;
            color: #000000;
        }

        h1,
        h2,
        h3 {
            color: #007bff;
            /* Blue accent */
        }

        pre {
            background-color: #f8f9fa;
            padding: 10px;
            border: 1px solid #dee2e6;
            border-radius: 5px;
            overflow-x: auto;
        }

        .content-section {
            margin-bottom: 30px;
        }
    </style>
</head>

<body>

    <div class="container">
        <div class="content-section">
            <h1>Week 7: Deep Learning and Neural Networks</h1>

            <h2>Implementing a Basic Neural Network with TensorFlow/Keras</h2>

            <h3>1. Import Necessary Libraries</h3>
            <pre><code>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense</code></pre>

            <h3>2. Load and Prepare Data</h3>
            <ul>
                <li>Load your dataset into a suitable format (e.g., NumPy array, Pandas DataFrame).</li>
                <li>Preprocess the data as necessary, including handling missing values, outliers, and feature scaling.
                </li>
                <li>Split the data into training and testing sets.</li>
            </ul>

            <h3>3. Create the Neural Network Model</h3>
            <p>Use the <code>Sequential</code> model in Keras to create a sequential model. Add layers to the model
                using the <code>Dense</code> layer, specifying the number of neurons and activation function for each
                layer.</p>
            <pre><code>model = Sequential()
model.add(Dense(128, activation='relu', input_dim=num_features))
model.add(Dense(64, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))</code></pre>

            <h3>4. Compile the Model</h3>
            <p>Specify the optimizer, loss function, and metrics to evaluate the model.</p>
            <pre><code>model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])</code></pre>

            <h3>5. Train the Model</h3>
            <p>Fit the model to the training data using the <code>fit</code> method.</p>
            <pre><code>model.fit(X_train, y_train, epochs=10, batch_size=32)</code></pre>

            <h3>6. Evaluate the Model</h3>
            <p>Evaluate the model's performance on the testing set.</p>
            <pre><code>loss, accuracy = model.evaluate(X_test, y_test)
print('Test accuracy:', accuracy)</code></pre>

            <h3>Example: Classifying the MNIST Dataset</h3>
            <pre><code>from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical

# Load the MNIST dataset
(X_train, y_train), (X_test, y_test) = mnist.load_data()

# Flatten the images
X_train = X_train.reshape(X_train.shape[0], -1)
X_test = X_test.reshape(X_test.shape[0], -1)

# Normalize the pixel values
X_train = X_train.astype('float32') / 255
X_test = X_test.astype('float32') / 255

# Convert class labels to one-hot encoding
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Create the neural network model
model = Sequential()
model.add(Dense(128, activation='relu', input_dim=784))
model.add(Dense(64, activation='relu'))
model.add(Dense(10, activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print('Test accuracy:', accuracy)</code></pre>

            <h3>Additional Tips</h3>
            <ul>
                <li><strong>Experiment with different architectures:</strong> Try different numbers of layers, neurons,
                    and activation functions.</li>
                <li><strong>Tune hyperparameters:</strong> Adjust hyperparameters like learning rate, batch size, and
                    regularization.</li>
                <li><strong>Use transfer learning:</strong> Leverage pre-trained models to accelerate training and
                    improve performance.</li>
                <li><strong>Consider regularization techniques:</strong> Techniques like dropout and L1/L2
                    regularization can help prevent overfitting.</li>
                <li><strong>Visualize the training process:</strong> Use tools like TensorBoard to monitor the loss and
                    accuracy during training.</li>
            </ul>

            <p>By following these steps and experimenting with different configurations, you can build and train
                effective neural networks for a variety of tasks.</p>
        </div>
    </div>

    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
</body>

</html>