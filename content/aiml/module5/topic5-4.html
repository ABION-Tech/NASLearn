<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Week 5: Unsupervised Learning - Clustering</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <style>
        body {
            background-color: white;
            color: black;
            font-family: Arial, sans-serif;
        }

        h1,
        h2,
        h3 {
            color: #007bff;
            /* Bootstrap primary color */
        }

        .card {
            border: none;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            margin-bottom: 20px;
        }

        .card-header {
            background-color: #007bff;
            color: white;
        }

        .highlight {
            background-color: #f0f8ff;
            /* Light blue background for emphasis */
            border-left: 5px solid #007bff;
            padding: 10px;
        }

        .steps-list {
            list-style-type: none;
            padding-left: 0;
        }

        .steps-list li {
            position: relative;
            padding-left: 20px;
        }

        .steps-list li:before {
            content: '•';
            position: absolute;
            left: 0;
            color: #007bff;
            /* Blue bullet point */
        }

        .footer {
            padding: 20px 0;
            text-align: center;
        }
    </style>
</head>

<body>
    <div class="module">
        <header class="module-header">
            <h1>Module 5: Neural Networks & Deep Learning</h1>
            <h2>Page 4: Evaluating and Improving Neural Networks</h2>
        </header>

        <section class="content">
            <article class="introduction">
                <h2>Why is Evaluation Important?</h2>
                <p>After training a neural network, it's crucial to evaluate how well it performs. A model might fit the
                    training data well but still perform poorly on new data. Evaluation helps ensure the model
                    generalizes effectively.</p>
            </article>

            <article class="evaluation-metrics">
                <h2>1. Key Evaluation Metrics</h2>
                <p>Different performance metrics are used depending on the type of problem the neural network is
                    solving.</p>

                <h3>Classification Metrics:</h3>
                <ul>
                    <li><strong>Accuracy:</strong> Measures the percentage of correct predictions.</li>
                    <li><strong>Precision:</strong> Measures how many predicted positives are actually correct.</li>
                    <li><strong>Recall (Sensitivity):</strong> Measures how many actual positives were correctly
                        predicted.</li>
                    <li><strong>F1 Score:</strong> Balances precision and recall.</li>
                    <li><strong>Confusion Matrix:</strong> Displays true positives, false positives, true negatives, and
                        false negatives.</li>
                    <li><strong>ROC Curve & AUC:</strong> Helps visualize classification performance.</li>
                </ul>

                <h3>Regression Metrics:</h3>
                <ul>
                    <li><strong>Mean Squared Error (MSE):</strong> Measures the average squared difference between
                        actual and predicted values.</li>
                    <li><strong>Mean Absolute Error (MAE):</strong> Measures the average absolute difference.</li>
                    <li><strong>R² Score:</strong> Measures how well the model explains the variance in data.</li>
                </ul>
            </article>

            <article class="train-test-split">
                <h2>2. Train-Test Split & Cross-Validation</h2>
                <p>To ensure a model’s generalization ability, it is split into training and testing sets:</p>
                <ul>
                    <li><strong>Training Set:</strong> Used to teach the model.</li>
                    <li><strong>Validation Set:</strong> Used to tune hyperparameters.</li>
                    <li><strong>Test Set:</strong> Used to evaluate final performance.</li>
                </ul>
                <p><strong>Cross-Validation:</strong> Further improves evaluation by splitting the dataset into multiple
                    parts and training on different subsets.</p>
            </article>

            <article class="bias-variance-tradeoff">
                <h2>3. Bias-Variance Tradeoff</h2>
                <p>Striking a balance between bias (underfitting) and variance (overfitting) is crucial.</p>
                <ul>
                    <li><strong>High Bias:</strong> The model is too simple and fails to capture patterns
                        (underfitting).</li>
                    <li><strong>High Variance:</strong> The model memorizes training data but fails on new data
                        (overfitting).</li>
                    <li><strong>Solution:</strong> Use techniques like regularization, cross-validation, and collecting
                        more data.</li>
                </ul>
            </article>

            <article class="regularization">
                <h2>4. Regularization Techniques</h2>
                <p>Regularization prevents overfitting and improves generalization.</p>
                <ul>
                    <li><strong>L1 Regularization (Lasso):</strong> Shrinks some weights to zero, promoting sparsity.
                    </li>
                    <li><strong>L2 Regularization (Ridge):</strong> Penalizes large weights, preventing excessive
                        complexity.</li>
                    <li><strong>Dropout:</strong> Randomly deactivates neurons during training to prevent reliance on
                        specific features.</li>
                    <li><strong>Batch Normalization:</strong> Normalizes inputs across mini-batches for faster and more
                        stable training.</li>
                </ul>
            </article>

            <article class="hyperparameter-tuning">
                <h2>5. Hyperparameter Tuning</h2>
                <p>Adjusting hyperparameters is key to optimizing neural network performance.</p>
                <ul>
                    <li><strong>Learning Rate:</strong> Controls step size in weight updates.</li>
                    <li><strong>Number of Hidden Layers & Neurons:</strong> Determines network complexity.</li>
                    <li><strong>Batch Size:</strong> Affects training stability and efficiency.</li>
                    <li><strong>Number of Epochs:</strong> Impacts convergence and risk of overfitting.</li>
                    <li><strong>Optimization Algorithm:</strong> Choice of Adam, SGD, or RMSprop affects training speed.
                    </li>
                </ul>
                <p>Grid search and random search can be used to find optimal hyperparameters.</p>
            </article>

            <article class="transfer-learning">
                <h2>6. Transfer Learning</h2>
                <p>Instead of training a model from scratch, pre-trained models can be used to improve performance,
                    especially when data is limited.</p>
                <ul>
                    <li><strong>Feature Extraction:</strong> Use existing layers of a trained model to extract features.
                    </li>
                    <li><strong>Fine-Tuning:</strong> Adjust the later layers of a pre-trained model to adapt to a
                        specific task.</li>
                    <li><strong>Common Pre-Trained Models:</strong> VGG, ResNet, and BERT (for NLP).</li>
                </ul>
            </article>

            <article class="ensemble-learning">
                <h2>7. Ensemble Learning</h2>
                <p>Combining multiple models often yields better results than a single model.</p>
                <ul>
                    <li><strong>Bagging:</strong> Train multiple models in parallel and average their outputs (e.g.,
                        Random Forests).</li>
                    <li><strong>Boosting:</strong> Train models sequentially, correcting mistakes along the way (e.g.,
                        AdaBoost, XGBoost).</li>
                    <li><strong>Stacking:</strong> Use multiple models and a meta-model to make final predictions.</li>
                </ul>
            </article>

            <article class="summary">
                <h2>Summary</h2>
                <p>To ensure a neural network performs well, evaluation metrics must be carefully examined, and
                    techniques such as regularization, hyperparameter tuning, transfer learning, and ensemble methods
                    should be applied. The next section will cover real-world applications of deep learning.</p>
            </article>
        </section>
    </div>
</body>

</html>