<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Core Algorithms</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            background-color: #fff;
            color: #000;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
        }

        .content-section {
            padding: 2rem 4rem;
        }

        h1,
        h2,
        h3 {
            margin-bottom: 1.5rem;
        }

        .course-title {
            color: #007bff;
        }

        .section-title {
            color: #007bff;
            font-weight: bold;
            margin-top: 2rem;
        }

        .custom-list {
            padding-left: 1.5rem;
        }

        .custom-list li {
            margin-bottom: 0.5rem;
        }

        .data-format-table {
            margin-top: 2rem;
        }

        .highlight {
            background-color: #e9f7fe;
            padding: 0.2rem 0.4rem;
            border-radius: 0.2rem;
        }

        .visualization-techniques img {
            width: 100%;
            height: auto;
            max-width: 450px;
            border: 1px solid #ccc;
            margin: 1rem 0;
        }
    </style>
</head>

<body>
    <div class="container mt-5">
        <h1 class="text-center">Artificial Intelligence (ML): Module 2: Machine Learning Fundamentals</h1>
        <h3 class="text-center">Topic 2: Core Algorithms</h3>

        <div class="section-title mt-4">Page 2: Understanding Key Machine Learning Algorithms</div>
        <div class="content-block">
            <p>Machine learning relies on algorithms to identify patterns, make predictions, and group data. Below, we
                explore three foundational algorithms—linear regression, decision trees, and K-means
                clustering—highlighting their use cases, advantages, and limitations.</p>
        </div>

        <div class="section-title mt-4">1. Linear Regression</div>
        <div class="content-block">
            <h4>Overview</h4>
            <p>Linear regression is a supervised learning algorithm used for predicting continuous values. It assumes a
                linear relationship between the input variables (features) and the output variable (target).</p>
            <h5>Formula</h5>
            <p>The model predicts the output (\( Y \)) based on the equation:</p>
            <pre><code>Y = mX + b</code></pre>
            <p>Where:</p>
            <ul>
                <li><strong>m:</strong> Slope of the line (how changes in \( X \) affect \( Y \)).</li>
                <li><strong>X:</strong> Independent variable (feature).</li>
                <li><strong>b:</strong> Intercept (the value of \( Y \) when \( X \) is 0).</li>
            </ul>
            <h5>Example Use Case</h5>
            <ul>
                <li><strong>Sales Forecasting:</strong> Predicting future sales based on advertising spend, past trends,
                    or seasonal factors.</li>
            </ul>
            <h5>Advantages</h5>
            <ul>
                <li>Simple to implement and interpret.</li>
                <li>Works well with linearly related data.</li>
            </ul>
            <h5>Limitations</h5>
            <ul>
                <li>Struggles with non-linear relationships.</li>
                <li>Sensitive to outliers, which can skew the regression line.</li>
            </ul>
        </div>

        <div class="section-title mt-4">2. Decision Trees</div>
        <div class="content-block">
            <h4>Overview</h4>
            <p>Decision trees are versatile algorithms used for classification and regression tasks. They resemble a
                flowchart, where decisions are made at each node based on feature values.</p>
            <h5>How It Works</h5>
            <ul>
                <li>Data is split into branches based on decision rules.</li>
                <li>Each branch leads to an outcome, either a predicted value or a class label.</li>
            </ul>
            <h5>Example Use Case</h5>
            <ul>
                <li><strong>Loan Approval:</strong> Classifying loan applications as approved or denied based on
                    criteria like income, credit score, and employment history.</li>
            </ul>
            <h5>Advantages</h5>
            <ul>
                <li>Intuitive and easy to interpret.</li>
                <li>Handles both numerical and categorical data.</li>
            </ul>
            <h5>Limitations</h5>
            <ul>
                <li>Prone to <strong>overfitting</strong>, especially with small datasets.</li>
                <li>May require pruning or ensemble methods (e.g., Random Forests) to improve generalization.</li>
            </ul>
        </div>

        <div class="section-title mt-4">3. K-Means Clustering</div>
        <div class="content-block">
            <h4>Overview</h4>
            <p>K-Means is an unsupervised learning algorithm that groups data into \( k \) clusters based on feature
                similarity. It minimizes the distance between data points and their cluster centroids.</p>
            <h5>How It Works</h5>
            <ol>
                <li>Initialize \( k \) cluster centroids randomly.</li>
                <li>Assign each data point to the nearest centroid.</li>
                <li>Recalculate centroids based on the mean position of assigned points.</li>
                <li>Repeat until the centroids stabilize.</li>
            </ol>
            <h5>Example Use Case</h5>
            <ul>
                <li><strong>Customer Segmentation:</strong> Grouping customers based on purchasing behavior to tailor
                    marketing strategies.</li>
            </ul>
            <h5>Advantages</h5>
            <ul>
                <li>Efficient for large datasets.</li>
                <li>Provides clear and distinct clusters.</li>
            </ul>
            <h5>Limitations</h5>
            <ul>
                <li>Requires the number of clusters (\( k \)) to be predefined.</li>
                <li>Sensitive to initial centroid positions and outliers.</li>
            </ul>
        </div>

        <div class="section-title mt-4">Conclusion</div>
        <div class="content-block">
            <p>By understanding these core algorithms, learners can tackle diverse machine learning problems, from
                predicting outcomes to uncovering hidden patterns in data. Practical applications and experience with
                these methods will deepen comprehension and skill.</p>
        </div>
    </div>

    <!-- Bootstrap JS and Popper.js -->
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.min.js"></script>
</body>


</html>