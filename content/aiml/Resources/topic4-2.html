<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Week 4: Supervised Learning - Classification</title>
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            background-color: white;
            color: black;
            font-family: Arial, sans-serif;
        }

        h1,
        h2,
        h3 {
            color: #007BFF;
            /* Blue accent */
        }

        .section {
            margin-bottom: 40px;
            border-bottom: 2px solid #007BFF;
            padding-bottom: 20px;
        }

        .algorithm {
            background-color: #f8f9fa;
            /* Light background for algorithms */
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
        }

        .advantages,
        .disadvantages {
            list-style-type: none;
            padding-left: 0;
        }

        .advantages li,
        .disadvantages li {
            margin-bottom: 10px;
        }
    </style>
</head>

<body>

    <div class="container mt-5">

        <div class="section">
            <h1>Week 4: Supervised Learning - Classification</h1>
            <h2>Decision Trees, SVM, k-NN, and Random Forests</h2>
            <p>In addition to logistic regression, several other classification algorithms are widely used in machine
                learning. These include decision trees, support vector machines (SVMs), k-nearest neighbors (k-NN), and
                random forests.</p>
        </div>

        <div class="section algorithm">
            <h3>1. Decision Trees</h3>
            <p><strong>Model:</strong> A tree-like structure where each node represents a decision based on a feature,
                and each branch represents a possible outcome.</p>
            <p><strong>How it works:</strong></p>
            <ol>
                <li>Start at the root node.</li>
                <li>Evaluate the feature at the current node.</li>
                <li>Follow the branch corresponding to the outcome.</li>
                <li>Repeat until a leaf node is reached, which represents the predicted class.</li>
            </ol>
            <p><strong>Advantages:</strong></p>
            <ul class="advantages">
                <li>Easy to interpret and explain.</li>
                <li>Can handle both numerical and categorical features.</li>
                <li>Can capture non-linear relationships.</li>
            </ul>
            <p><strong>Disadvantages:</strong></p>
            <ul class="disadvantages">
                <li>Can be prone to overfitting, especially with deep trees.</li>
            </ul>
        </div>

        <div class="section algorithm">
            <h3>2. Support Vector Machines (SVMs)</h3>
            <p><strong>Model:</strong> Find a hyperplane that separates the data into different classes with the maximum
                margin.</p>
            <p><strong>Kernel trick:</strong> Map the data to a higher-dimensional space to find a separating
                hyperplane.</p>
            <p><strong>Types:</strong></p>
            <ul>
                <li>Linear SVM: For linearly separable data.</li>
                <li>Nonlinear SVM: Uses kernel functions to handle non-linear relationships.</li>
            </ul>
            <p><strong>Advantages:</strong></p>
            <ul class="advantages">
                <li>Effective for high-dimensional data.</li>
                <li>Robust to outliers.</li>
            </ul>
            <p><strong>Disadvantages:</strong></p>
            <ul class="disadvantages">
                <li>Can be computationally expensive for large datasets.</li>
            </ul>
        </div>

        <div class="section algorithm">
            <h3>3. k-Nearest Neighbors (k-NN)</h3>
            <p><strong>Model:</strong> Classify new data points based on the majority class of their k nearest neighbors
                in the training set.</p>
            <p><strong>Choosing k:</strong> The value of k can affect the model's performance. A small k can lead to
                overfitting, while a large k can lead to underfitting.</p>
            <p><strong>Advantages:</strong></p>
            <ul class="advantages">
                <li>Simple to implement.</li>
                <li>No training required.</li>
                <li>Can handle non-linear relationships.</li>
            </ul>
            <p><strong>Disadvantages:</strong></p>
            <ul class="disadvantages">
                <li>Can be computationally expensive for large datasets.</li>
                <li>Sensitive to the choice of distance metric.</li>
            </ul>
        </div>

        <div class="section algorithm">
            <h3>4. Random Forests</h3>
            <p><strong>Model:</strong> An ensemble of decision trees, each trained on a random subset of the data and
                features.</p>
            <p><strong>Advantages:</strong></p>
            <ul class="advantages">
                <li>Reduces overfitting by averaging the predictions of multiple trees.</li>
                <li>Can handle both numerical and categorical features.</li>
                <li>Can capture non-linear relationships.</li>
            </ul>
            <p><strong>Disadvantages:</strong></p>
            <ul class="disadvantages">
                <li>Can be computationally expensive for large datasets.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Choosing the Right Algorithm</h2>
            <p>The best classification algorithm depends on the characteristics of your data and the specific
                requirements of your problem. Consider the following factors:</p>
            <ul>
                <li><strong>Data type:</strong> Numerical, categorical, or a combination.</li>
                <li><strong>Number of features:</strong> The dimensionality of the data.</li>
                <li><strong>Class balance:</strong> Whether the classes are balanced or imbalanced.</li>
                <li><strong>Computational resources:</strong> The available computing power.</li>
            </ul>
            <p>By understanding these classification algorithms and their strengths and weaknesses, you can select the
                most appropriate algorithm for your specific task.</p>
        </div>

    </div>

    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
</body>

</html>